{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2. Clustering using k-means\n",
    "\n",
    "### Student ID: 915030521\n",
    "### Student Name: Chenghan Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/furinkazan/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/mpl_toolkits/', '/Users/furinkazan/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/mpl_toolkits/', '/Users/furinkazan/Box/STA_142B/Project_2', '/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python37.zip', '/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7', '/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload', '', '/Users/furinkazan/Library/Python/3.7/lib/python/site-packages', '/usr/local/lib/python3.7/site-packages', '/usr/local/Cellar/protobuf/3.11.4/libexec/lib/python3.7/site-packages', '/usr/local/lib/python3.7/site-packages/IPython/extensions', '/Users/furinkazan/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# All Import Statements Defined Here\n",
    "# Note: Do not change anything\n",
    "\n",
    "import numpy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(sys.path)\n",
    "# Do not use any other packages below here in your code before part 4\n",
    "# install Basemap before you start\n",
    "\n",
    "import pandas as pd\n",
    "import mpl_toolkits\n",
    "mpl_toolkits.__path__.append('/anaconda3-5.3.1/lib/python3.7/site-packages/mpl_toolkits/')\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from pylab import rcParams\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Implementing k-means algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete what is missing to implement the k means algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class k_means:\n",
    "    \n",
    "    def __init__(self, data: numpy.ndarray, d: int, k: int , tol: float, max_iter: int):\n",
    "        \"\"\"\n",
    "        data: data to cluster\n",
    "        d:dimension of the data\n",
    "        k: prespecified number of clusters\n",
    "        tol: convergence criterion\n",
    "        max_iter: maximum number of iterations allowed\n",
    "        \"\"\"\n",
    "        self.partitions={i:[] for i in range(k) }\n",
    "        self.labels=[] # list of numbers with values from 0 to k-1\n",
    "        self.d=d\n",
    "        self.n=data.shape[0]  # num of samples \n",
    "        self.counter=0\n",
    "    \n",
    "        ### your code starts here\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.data = data\n",
    "        self.update_flag = True\n",
    "        self.centers = None\n",
    "        self.labels = {i:[] for i in range(self.k)}\n",
    "        self.cost = 0\n",
    "        ### end of your code\n",
    "    \n",
    "    def initialize_centers(self, method: int):\n",
    "        \"\"\"\n",
    "        method = 1:\n",
    "        randomly pick k points from the data as centers\n",
    "        \"\"\"\n",
    "        if method==0:\n",
    "            self.centers=data[:self.k,:]\n",
    "            \n",
    "        elif method==1:\n",
    "        ### your code starts here\n",
    "            rand_index = numpy.random.choice(self.n, self.k, replace=False)\n",
    "            self.centers = self.data[rand_index, :]\n",
    "            return self.centers\n",
    "        else:\n",
    "            print(\"Method needs to be either 0 or 1\")\n",
    "        ### end of your code\n",
    "        \n",
    "    def search(self):\n",
    "        \"\"\"\n",
    "        update the partitions and the next centers;\n",
    "        here we use centroids for k-means method\n",
    "        \"\"\"\n",
    "        self.partitions={i:[] for i in range(self.k)}\n",
    "        self.next_centers=numpy.array([])\n",
    "        \n",
    "        ### your code starts here\n",
    "        # update the partitions\n",
    "        for sample in range(self.n):  # loop through all the samples\n",
    "            closest_sample = []  # initialize closest samples as a list\n",
    "            for center in range(len(self.centers)):  # loop through all picked centers\n",
    "                euc_dist = numpy.linalg.norm(self.data[sample] - self.centers[center])\n",
    "                closest_sample.append(euc_dist) \n",
    "            closest_index = numpy.argmin(closest_sample)  # return the index of closest sample \n",
    "            self.partitions[sample] = closest_index\n",
    "            \n",
    "        # update the next centers\n",
    "        for i in range(len(self.centers)):  # loop through the number of clusters\n",
    "            partitions_index = self.partitions[i]\n",
    "            selected_centers = self.data[partitions_index]\n",
    "            mean_dist = np.mean(selected_centers)\n",
    "            self.next_centers.append(mean_dist)\n",
    "        self.centers = self.next_centers  # update new center\n",
    "        ### end of your code\n",
    "        \n",
    "    def is_updated(self):\n",
    "        \"\"\"\n",
    "        return True if update is done, but has not yet converged; False otherwise;\n",
    "        the convergence criterion is the sum of absolute relative differences (between self.centers and \n",
    "        self.next_centers) smaller than tol\n",
    "        \"\"\"\n",
    "        \n",
    "        ### your code starts here\n",
    "        converge_criterion = sum(abs(self.centers - self.next_centers))\n",
    "        if not self.update_flag:\n",
    "            print(\"Update_flag needs to be defaulted as True\")\n",
    "        if converge_criterion > self.tol:\n",
    "            return self.update_flag\n",
    "        else:\n",
    "            self.update_flag = False\n",
    "            return self.update_flag\n",
    "        ### end of your code\n",
    "        \n",
    "    def fit_model(self):\n",
    "        \"\"\"\n",
    "        function to fit the k-means algorithms using the above functions\n",
    "        \"\"\"\n",
    "        self.initialize_centers(1)\n",
    "        ### your code starts here\n",
    "        for it in range(self.max_iter):  # perform iterations \n",
    "            self.search()\n",
    "            if not self.is_updated():\n",
    "                print(\"The K-means algorithm is converged!\")\n",
    "                break\n",
    "        ### your code ends here\n",
    "        self.get_labels()\n",
    "\n",
    "    def set_k(self,k):\n",
    "        self.k=k\n",
    "        \n",
    "    def predict(self):\n",
    "        distances = [ numpy.linalg.norm( pt-c ) for c in self.centroids ]\n",
    "        cluster_label = distances.index( min(distances) )\n",
    "        return cluster_label\n",
    "\n",
    "    def get_labels(self):\n",
    "        ### your code starts here\n",
    "        for center in range(len(self.centers)):  # loop through all picked centers\n",
    "            for closest_index in self.partitions[center]:\n",
    "                self.labels[closest_index] = center\n",
    "        self.labels = np.array(self.labels)\n",
    "        ### end of your code\n",
    "        return self.labels\n",
    "    \n",
    "    def get_centers(self):\n",
    "        return self.centers\n",
    "    \n",
    "    def get_clusters(self):\n",
    "        return self.partitions\n",
    "\n",
    "    def get_cost(self):\n",
    "        \"\"\"\n",
    "        Here we use within cluster sum of squares as cost \n",
    "        \"\"\"\n",
    "        ### your code starts here\n",
    "        for sample in range(self.n):  # loop through all the samples\n",
    "            labels = self.labels[sample]\n",
    "            iter_cost = numpy.linalg.norm(self.data[i,:] - self.centers[labels, :])\n",
    "            self.cost += iter_cost\n",
    "        ### end of your code\n",
    "        return self.cost\n",
    "        \n",
    "    def plot_clusters(self):\n",
    "        if self.d>2:\n",
    "            print(\"Dimension too large!\")\n",
    "            return \n",
    "        if self.labels==[]:\n",
    "            self.fit_model()\n",
    "        plt.scatter( self.data[:,0] , self.data[:,1], c=self.labels ,s=3)\n",
    "        plt.scatter( np.array(self.centers)[:,0],np.array(self.centers)[:,1] ,marker='*',c=list(range(self.k)) ,s=300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Implementing criteria to evaluate clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clustering_eval_metrics:\n",
    "    def __init__(self, labels: list ,true_labels=None): # label must be between 0 to number_of_labels - 1\n",
    "        self.labels=numpy.array(labels)\n",
    "        self.true_labels=true_labels\n",
    "        self.cmat=None\n",
    "        self.ars=None\n",
    "        \n",
    "    def set_true_labels(self, true_labels):\n",
    "        self.true_labels=numpy.array(true_labels)\n",
    "    \n",
    "    def contingency_matrix(self): \n",
    "        \"\"\"\n",
    "        return a contingency matrix\n",
    "        \"\"\"\n",
    "        ### your code starts here\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ### end of your code\n",
    "        \n",
    "        return self.cmat\n",
    "        \n",
    "    def adjusted_rand_score(self):\n",
    "        \"\"\"\n",
    "        return ARI/ARS\n",
    "        \"\"\"\n",
    "        ### your code starts here\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ### end of your code\n",
    "\n",
    "        return self.ars\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. k-medoid algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a class called pam to implement the k-medoid algorithm. It should have a similar structure as the k_means class as we implemented before. Write the code as concise as possible. Any code that exceeds 40 lines will get penalized.\n",
    "\n",
    "pam should take one more parameter p. the input will look like\n",
    "\n",
    "(data: numpy.ndarray, d: int, k: int , tol: float, max_iter: int, p: float)\n",
    "\n",
    "p indicates whtat Lp norm is used. $ |x|_{L_p}=( x_1^p+\\ldots+x_d^p  )^{1/p}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Your code starts here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Simulation Study \n",
    "\n",
    "### You may choose not to use the functions written above to finish this part. Then, you automatically lose all the points from Part 1~3.\n",
    "\n",
    "Sample $60$ data points each from the following distributions each\n",
    "\n",
    "$$ X_1\\sim N\\bigg(\\begin{pmatrix}\n",
    "0\\\\\n",
    "0\\end{pmatrix},\\begin{pmatrix}\n",
    "1 & 0\\\\\n",
    "0 & 1 \\end{pmatrix}\\bigg),X_2\\sim N\\bigg(\\begin{pmatrix}\n",
    "3\\\\\n",
    "2\\end{pmatrix},\\begin{pmatrix}\n",
    "2 & 1\\\\\n",
    "1 & 1 \\end{pmatrix}\\bigg)\n",
    ", X_3\\sim N\\bigg(\\begin{pmatrix}\n",
    "5\\\\\n",
    "0\\end{pmatrix},\\begin{pmatrix}\n",
    "2 & 1\\\\\n",
    "1 & 1 \\end{pmatrix}\\bigg) $$\n",
    "\n",
    "to form a sample of size $180$.  Use numpy.random.multivariate_normal() and set numpy.random.seed(20) in front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=numpy.array([])\n",
    "true_label=numpy.array([])\n",
    "\n",
    "### your code starts here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### your code ends here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Apply k-means method (set k=3) to the simulated data set. Plot different clusters and their centers. Also calculate the adjusted rand score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2a Apply pam method (set k=3) to the simulated data set. Plot different clusters and their centers using the L_p \"norm\" when p=.1 and p=2. Also calculate the adjusted rand score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2b Can you compare these results and analyze quantitatively the cause of the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 How to choose k? First interpret the plot that you get from the code below, then come up with a procedure using this plot to find a k. What's k you would like to use? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss=[]\n",
    "km=k_means(data, 2, 1,1e-7,500)\n",
    "for i in range(1,16):\n",
    "    km.k=i\n",
    "    km.fit_model()\n",
    "    wcss.append(km.get_cost())\n",
    "plt.plot(list(range(1,16)),wcss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Segment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "\n",
    "\t\t\n",
    "<h4 align = \"center\">\n",
    "Environment Canada    \n",
    "Monthly Values for July - 2015\t\n",
    "</h4>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table {\n",
    "    font-family: arial, sans-serif;\n",
    "    border-collapse: collapse;\n",
    "    width: 100%;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "    border: 1px solid #dddddd;\n",
    "    text-align: left;\n",
    "    padding: 8px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "    background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Name in the table</th>\n",
    "    <th>Meaning</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Stn_Name</font></td>\n",
    "    <td><font color = \"green\"><strong>Station Name</font</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Lat</font></td>\n",
    "    <td><font color = \"green\"><strong>Latitude (North+, degrees)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Long</font></td>\n",
    "    <td><font color = \"green\"><strong>Longitude (West - , degrees)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Prov</td>\n",
    "    <td>Province</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tm</td>\n",
    "    <td>Mean Temperature (°C)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTm</td>\n",
    "    <td>Days without Valid Mean Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>D</td>\n",
    "    <td>Mean Temperature difference from Normal (1981-2010) (°C)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"black\">Tx</font></td>\n",
    "    <td><font color = \"black\">Highest Monthly Maximum Temperature (°C)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTx</td>\n",
    "    <td>Days without Valid Maximum Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"black\">Tn</font></td>\n",
    "    <td><font color = \"black\">Lowest Monthly Minimum Temperature (°C)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTn</td>\n",
    "    <td>Days without Valid Minimum Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S</td>\n",
    "    <td>Snowfall (cm)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwS</td>\n",
    "    <td>Days without Valid Snowfall</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S%N</td>\n",
    "    <td>Percent of Normal (1981-2010) Snowfall</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>P</font></td>\n",
    "    <td><font color = \"green\"><strong>Total Precipitation (mm)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwP</td>\n",
    "    <td>Days without Valid Precipitation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>P%N</td>\n",
    "    <td>Percent of Normal (1981-2010) Precipitation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S_G</td>\n",
    "    <td>Snow on the ground at the end of the month (cm)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Pd</td>\n",
    "    <td>Number of days with Precipitation 1.0 mm or more</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>BS</td>\n",
    "    <td>Bright Sunshine (hours)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwBS</td>\n",
    "    <td>Days without Valid Bright Sunshine</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>BS%</td>\n",
    "    <td>Percent of Normal (1981-2010) Bright Sunshine</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>HDD</td>\n",
    "    <td>Degree Days below 18 °C</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>CDD</td>\n",
    "    <td>Degree Days above 18 °C</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Stn_No</td>\n",
    "    <td>Climate station identifier (first 3 digits indicate   drainage basin, last 4 characters are for sorting alphabetically).</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>NA</td>\n",
    "    <td>Not Available</td>\n",
    "  </tr>\n",
    "\n",
    "\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='weather.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df = df[pd.notnull(df[\"Tm\"])]\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (14,10)\n",
    "llon=-140\n",
    "ulon=-50\n",
    "llat=40\n",
    "ulat=65\n",
    "df = df[(df['Long'] > llon) & (df['Long'] < ulon) & (df['Lat'] > llat) &(df['Lat'] < ulat)]\n",
    "\n",
    "my_map = Basemap(projection='merc',\n",
    "            resolution = 'l', area_thresh = 1000.0,\n",
    "            llcrnrlon=llon, llcrnrlat=llat,\n",
    "            urcrnrlon=ulon, urcrnrlat=ulat) \n",
    "my_map.drawcoastlines()\n",
    "my_map.drawcountries()\n",
    "my_map.shadedrelief()\n",
    "\n",
    "\n",
    "## this is to change longitude and latitude to coordinates\n",
    "\n",
    "xs,ys = my_map(np.asarray(df.Long), np.asarray(df.Lat))\n",
    "df['xm']= xs.tolist()\n",
    "df['ym'] =ys.tolist()\n",
    "\n",
    "# plot the stations on the map\n",
    "for index,row in df.iterrows():\n",
    "    my_map.plot(row.xm, row.ym,markerfacecolor =([1,0,0]),  marker='o', markersize= 5, alpha = 0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following, you'll work on two datasets data1 (segmentation based on location data only) and data2 (segmentation based on location data as well as the temperature data) to perform k means methods with an appropriate k to do clustering and then label the clusters on two separate maps. You need to justify every decisions you make by appropriate plots or reasoning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do not change anything in this block\n",
    "data1= df[['xm','ym']].to_numpy()\n",
    "data2 = df[['xm','ym','Tx','Tm','Tn']].to_numpy()\n",
    "\n",
    "data1 = np.nan_to_num(data1)\n",
    "data1 = StandardScaler().fit_transform(data1)\n",
    "data2 = np.nan_to_num(data2)\n",
    "data2 = StandardScaler().fit_transform(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add your code for problem 3 from part B below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data - see notebook on \"Dimension Reduction, PCA, kernel PCA, Part 1\"\n",
    "\n",
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peform hierarchical clustering on the states using complete linkage clustering \n",
    "# (using Euclidean distance) and plot the corresponding denrogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the states in each cluster and print them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now standardize the data and perform hierarchical clustering as above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a \"reasonable\" partition by considering the dedrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put your answer to Problem 3, part (d) here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Submit both a pdf file and your original jupyter notebook on canvas.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
