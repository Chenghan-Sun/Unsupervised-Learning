{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2. Clustering using k-means\n",
    "\n",
    "### Student ID: 915030521\n",
    "### Student Name: Chenghan Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Import Statements Defined Here\n",
    "# Note: Do not change anything\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Do not use any other packages below here in your code before part 4\n",
    "# install Basemap before you start\n",
    "\n",
    "import pandas as pd\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "from pylab import rcParams\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Implementing k-means algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete what is missing to implement the k means algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class k_means:\n",
    "    \n",
    "    def __init__(self, data: np.ndarray, d: int, k: int , tol: float, max_iter: int):\n",
    "        \"\"\"\n",
    "        data: data to cluster\n",
    "        d:dimension of the data\n",
    "        k: prespecified number of clusters\n",
    "        tol: convergence criterion\n",
    "        max_iter: maximum number of iterations allowed\n",
    "        \"\"\"\n",
    "        self.partitions={i:[] for i in range(k) }\n",
    "        self.labels=[] # list of numbers with values from 0 to k-1\n",
    "        self.d=d\n",
    "        self.n=data.shape[0]  # num of samples: 180\n",
    "        self.counter=0\n",
    "    \n",
    "        ### your code starts here\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.data = data\n",
    "        self.update_flag = True\n",
    "        self.centers = None\n",
    "        self.cost = 0\n",
    "        ### end of your code\n",
    "    \n",
    "    def initialize_centers(self, method: int):\n",
    "        \"\"\"\n",
    "        method = 1:\n",
    "        randomly pick k points from the data as centers\n",
    "        \"\"\"\n",
    "        if method==0:\n",
    "            self.centers=data[:self.k,:]\n",
    "            \n",
    "        elif method==1:\n",
    "        ### your code starts here\n",
    "            # K initial centers are generated at random\n",
    "            # select random data points w/o replacement\n",
    "            self.set_k(self.k)\n",
    "            rand_index = np.random.choice(self.n, self.k, replace=False) \n",
    "            self.centers = self.data[rand_index, :]\n",
    "            return self.centers\n",
    "        else:\n",
    "            raise ValueError(\"Method needs to be either 0 or 1\")\n",
    "        ### end of your code\n",
    "        \n",
    "    def search(self):\n",
    "        \"\"\"\n",
    "        update the partitions and the next centers;\n",
    "        here we use centroids for k-means method\n",
    "        \"\"\"\n",
    "        self.partitions={i:[] for i in range(self.k)}\n",
    "        self.next_centers=np.array([])\n",
    "        \n",
    "        ### your code starts here\n",
    "        # update the partitions\n",
    "        for sample in range(self.n):  # loop through all the samples\n",
    "            closest_samples = []  # initialize closest samples as a list\n",
    "            for center in range(self.centers.shape[0]):  # loop through all picked centers\n",
    "                euc_dist = np.linalg.norm(self.data[sample] - self.centers[center])\n",
    "                closest_samples.append(euc_dist)\n",
    "            \n",
    "            # closest_index = np.argmin(closest_samples) \n",
    "            target_sample = np.min(closest_samples)  # use for minimum index checker \n",
    "            # get the index/indicies of closest sample\n",
    "            closest_index = [i for i,j in enumerate(closest_samples) if j == target_sample] \n",
    "            \n",
    "            # in case of multiple closest indicies\n",
    "            if len(closest_index) != 1:  \n",
    "                closest_index = int(np.random.choice(closest_index, 1))\n",
    "            self.partitions[closest_index[0]].append(sample)  # update new partitions\n",
    "            \n",
    "        # update the next centers\n",
    "        next_centers_list = []  # list of new centers \n",
    "        for i in range(len(self.centers)):  # loop through the number of clusters\n",
    "            partitions_index = self.partitions[i]\n",
    "            selected_centers = self.data[partitions_index]  # find each new \"center\"\n",
    "            mean_dist = np.mean(selected_centers, axis=0)\n",
    "            next_centers_list.append(mean_dist)\n",
    "        self.next_centers = np.array(next_centers_list)  # form the new centers \n",
    "        ### end of your code\n",
    "        \n",
    "    def is_updated(self):\n",
    "        \"\"\"\n",
    "        return True if update is done, but has not yet converged; False otherwise;\n",
    "        the convergence criterion is the sum of absolute relative differences (between self.centers and \n",
    "        self.next_centers) smaller than tol\n",
    "        \"\"\"\n",
    "        \n",
    "        ### your code starts here\n",
    "        converge_criterion = np.linalg.norm((self.centers - self.next_centers), ord=1)\n",
    "        if not self.update_flag:\n",
    "            print(\"Update_flag needs to be defaulted as True\")\n",
    "            \n",
    "        if converge_criterion > self.tol:\n",
    "            return self.update_flag\n",
    "        else:\n",
    "            self.update_flag = False\n",
    "            return self.update_flag\n",
    "        ### end of your code\n",
    "        \n",
    "    def fit_model(self):\n",
    "        \"\"\"\n",
    "        function to fit the k-means algorithms using the above functions\n",
    "        \"\"\"\n",
    "        self.initialize_centers(1)  # method = 1 \n",
    "        ### your code starts here\n",
    "        for it in range(self.max_iter):  # perform iterations \n",
    "            self.search()\n",
    "            # print(self.update_flag)\n",
    "            if not self.is_updated():\n",
    "                print(f\"The K-means algorithm is converged at iteration number = {it}\")\n",
    "                break\n",
    "            self.centers = self.next_centers  # update new center\n",
    "        ### your code ends here\n",
    "        self.get_labels()\n",
    "\n",
    "    def set_k(self,k):\n",
    "        self.k=k\n",
    "    \n",
    "    # not used but changed as Lingfei mentioned \n",
    "    def predict(self,pt):\n",
    "        distances = [ numpy.linalg.norm( pt-c ) for c in self.centers ]\n",
    "        cluster_label = distances.index( min(distances) )\n",
    "        return cluster_label\n",
    "\n",
    "    def get_labels(self):\n",
    "        ### your code starts here\n",
    "        self.labels = np.empty(self.n)\n",
    "        for center in range(len(self.centers)):  # loop through all picked centers\n",
    "            # print(self.partitions[center])\n",
    "            for closest_index in self.partitions[center]:\n",
    "                self.labels[closest_index] = center  # assign labels \n",
    "        self.labels = np.array(self.labels)\n",
    "        ### end of your code\n",
    "        return self.labels\n",
    "    \n",
    "    def get_centers(self):\n",
    "        return self.centers\n",
    "    \n",
    "    def get_clusters(self):\n",
    "        return self.partitions\n",
    "\n",
    "    def get_cost(self):\n",
    "        \"\"\"\n",
    "        Here we use within cluster sum of squares as cost \n",
    "        \"\"\"\n",
    "        ### your code starts here\n",
    "        for sample in range(self.n):  # loop through all the samples\n",
    "            label = int(self.labels[sample])  # label index\n",
    "            iter_cost = np.linalg.norm(self.data[i] - self.centers[label]) ** 2\n",
    "            self.cost += iter_cost\n",
    "        ### end of your code\n",
    "        return self.cost\n",
    "        \n",
    "    def plot_clusters(self):\n",
    "        if self.d>2:\n",
    "            print(\"Dimension too large!\")\n",
    "            return \n",
    "        if self.labels==[]:\n",
    "            self.fit_model()\n",
    "        plt.scatter( self.data[:,0] , self.data[:,1], c=self.labels, s=3)\n",
    "        plt.scatter( np.array(self.centers)[:,0],np.array(self.centers)[:,1] ,marker='*',c=list(range(self.k)) ,s=300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Implementing criteria to evaluate clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clustering_eval_metrics:\n",
    "    def __init__(self, labels: list ,true_labels=None): # label must be between 0 to number_of_labels - 1\n",
    "        self.labels=np.array(labels)\n",
    "        self.true_labels=true_labels\n",
    "        self.cmat=None\n",
    "        self.ars=None\n",
    "        \n",
    "    def set_true_labels(self, true_labels):\n",
    "        self.true_labels=np.array(true_labels)\n",
    "        \n",
    "    def contingency_matrix(self): \n",
    "        \"\"\"\n",
    "        return a contingency matrix\n",
    "        \"\"\"\n",
    "        ### your code starts here\n",
    "        # here I referred sklearn.metrics.cluster.contingency_matrix to build my own contingency matrix\n",
    "        pred_clusters, pred_cluster_index = np.unique(self.labels, return_inverse=True)  # return the indices of ar\n",
    "        true_clusters, true_clusters_index = np.unique(self.true_labels, return_inverse=True)  # return the indices of ar\n",
    "        num_pred_clusters = pred_clusters.shape[0]  # get dimension sample size \n",
    "        num_true_clusters = true_clusters.shape[0]  # get dimension sample size\n",
    "        \n",
    "        # initialize the contingency matrix\n",
    "        if num_pred_clusters >= num_true_clusters:\n",
    "            n_clusters = num_pred_clusters\n",
    "        else:\n",
    "            n_clusters = num_true_clusters\n",
    "        self.cmat = np.zeros((n_clusters, n_clusters))\n",
    "        \n",
    "        # fill-in the contingency matrix\n",
    "        for pos in range(len(true_clusters_index)):\n",
    "            self.cmat[true_clusters_index[pos], pred_cluster_index[pos]] += 1\n",
    "        ### end of your code\n",
    "        \n",
    "        return self.cmat\n",
    "        \n",
    "    def adjusted_rand_score(self):\n",
    "        \"\"\"\n",
    "        return ARI/ARS\n",
    "        \"\"\"\n",
    "        ### your code starts here\n",
    "        # firstly, check input dimensions \n",
    "        if self.labels.ndim != 1:\n",
    "            raise ValueError(\n",
    "                f\"labels_pred must be 1D: shape is: {labels_pred.shape}\")\n",
    "        if self.true_labels.ndim != 1:\n",
    "            raise ValueError(\n",
    "                f\"labels_true must be 1D: shape is: {labels_true.shape}\")\n",
    "        \n",
    "        # get labels dimentionalities, similar steps as building contingency_matrix\n",
    "        num_samples = self.true_labels.shape[0]\n",
    "        pred_clusters = np.unique(self.labels)\n",
    "        num_pred_clusters = pred_clusters.shape[0]\n",
    "        true_clusters = np.unique(self.true_labels)\n",
    "        num_true_clusters = true_clusters.shape[0]\n",
    "        \n",
    "        # Check special limit cases: no clustering or\n",
    "        # trivial clustering where each document is assigned a unique cluster,\n",
    "        # which refers perfect matching case hence return 1\n",
    "        # Here I referred sklearn.metrics.adjusted_rand_score to for ARI calculation\n",
    "        if (num_true_clusters == num_pred_clusters == 1 or num_true_clusters == num_pred_clusters == 0 \\\n",
    "            or num_true_clusters == num_pred_clusters == num_samples):\n",
    "            return 1\n",
    "        else:\n",
    "            self.cmat = self.contingency_matrix()\n",
    "            \n",
    "        # calculate ARI using the contingency matrix \n",
    "        # using the equation of adjusted Rand index \n",
    "        # make a sub-helper function\n",
    "        def _helper_comb(n):\n",
    "            return n*(n-1)/2\n",
    "\n",
    "        # Here I referred sklearn.metrics.adjusted_rand_score to for ARI calculation\n",
    "        sum_comb_1 = sum(_helper_comb(n1) for n1 in np.ravel(self.cmat.sum(axis=1)))\n",
    "        sum_comb_2 = sum(_helper_comb(n2) for n2 in np.ravel(self.cmat.sum(axis=0)))\n",
    "        comb_mean = (sum_comb_1 + sum_comb_2) / 2\n",
    "        comb_prod = (sum_comb_1 * sum_comb_2) / _helper_comb(num_samples)\n",
    "\n",
    "        # last component: calculate summation of combinations by loops \n",
    "        sum_comb = 0  # initialize summation of combinations\n",
    "        for i in range(len(self.cmat)):\n",
    "            for j in range(len(self.cmat[0])):\n",
    "                component = self.cmat[i][j]\n",
    "                sum_comb += _helper_comb(component)\n",
    "\n",
    "        self.ars = (sum_comb - comb_prod) / (comb_mean - comb_prod)\n",
    "        ### end of your code\n",
    "        return self.ars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. k-medoid algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a class called pam to implement the k-medoid algorithm. It should have a similar structure as the k_means class as we implemented before. Write the code as concise as possible. Any code that exceeds 40 lines will get penalized.\n",
    "\n",
    "pam should take one more parameter p. the input will look like\n",
    "\n",
    "(data: numpy.ndarray, d: int, k: int , tol: float, max_iter: int, p: float)\n",
    "\n",
    "p indicates whtat Lp norm is used. $ |x|_{L_p}=( x_1^p+\\ldots+x_d^p  )^{1/p}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Your code starts here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Simulation Study \n",
    "\n",
    "### You may choose not to use the functions written above to finish this part. Then, you automatically lose all the points from Part 1~3.\n",
    "\n",
    "Sample $60$ data points each from the following distributions each\n",
    "\n",
    "$$ X_1\\sim N\\bigg(\\begin{pmatrix}\n",
    "0\\\\\n",
    "0\\end{pmatrix},\\begin{pmatrix}\n",
    "1 & 0\\\\\n",
    "0 & 1 \\end{pmatrix}\\bigg),X_2\\sim N\\bigg(\\begin{pmatrix}\n",
    "3\\\\\n",
    "2\\end{pmatrix},\\begin{pmatrix}\n",
    "2 & 1\\\\\n",
    "1 & 1 \\end{pmatrix}\\bigg)\n",
    ", X_3\\sim N\\bigg(\\begin{pmatrix}\n",
    "5\\\\\n",
    "0\\end{pmatrix},\\begin{pmatrix}\n",
    "2 & 1\\\\\n",
    "1 & 1 \\end{pmatrix}\\bigg) $$\n",
    "\n",
    "to form a sample of size $180$.  Use numpy.random.multivariate_normal() and set numpy.random.seed(20) in front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the sample size = (180, 2)\n"
     ]
    }
   ],
   "source": [
    "data=np.array([])\n",
    "true_labels=np.array([])\n",
    "\n",
    "### your code starts here\n",
    "np.random.seed(20)  # set seed as required \n",
    "\n",
    "# begin simulation data \n",
    "sample = 60\n",
    "X1 = np.random.multivariate_normal([0,0], [[1,0], [0,1]], sample)\n",
    "X2 = np.random.multivariate_normal([3,2], [[2,1], [1,1]], sample)\n",
    "X3 = np.random.multivariate_normal([5,0], [[2,1], [1,1]], sample)\n",
    "\n",
    "# insert into given data container \n",
    "data = np.concatenate([X1, X2, X3], axis=0)\n",
    "print(f\"Shape of the sample size = {data.shape}\")\n",
    "# print(data[0, :])\n",
    "\n",
    "true_labels = np.concatenate([[0]*sample,[1]*sample,[2]*sample])\n",
    "# print(true_label)\n",
    "### your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Apply k-means method (set k=3) to the simulated data set. Plot different clusters and their centers. Also calculate the adjusted rand score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The K-means algorithm is converged at iteration number = 7\n",
      "It's reported the adjusted rand score of my K-means algorithm = 0.7382334038133738\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_k = 3\n",
    "KMs = k_means(data = data, d = data.shape[1], k = global_k, tol = 0.01, max_iter = 100)\n",
    "\n",
    "# plot\n",
    "KMs.plot_clusters()\n",
    "pred_label = KMs.labels\n",
    "# print(pred_label)\n",
    "\n",
    "# report adjusted rand score (ARS)\n",
    "KMs_metrics = clustering_eval_metrics(pred_label, true_labels)\n",
    "KMs_metrics.contingency_matrix()\n",
    "print(f\"It's reported the adjusted rand score of my K-means algorithm = {KMs_metrics.adjusted_rand_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2a Apply pam method (set k=3) to the simulated data set. Plot different clusters and their centers using the L_p \"norm\" when p=.1 and p=2. Also calculate the adjusted rand score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2b Can you compare these results and analyze the cause of the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 How to choose k? First interpret the plot that you get from the code below, then come up with a procedure using this plot to find a k. What's k you would like to use? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss=[]\n",
    "km=k_means(data, 2, 1,1e-7,500)\n",
    "for i in range(1,16):\n",
    "    km.k=i\n",
    "    km.fit_model()\n",
    "    wcss.append(km.get_cost())\n",
    "plt.plot(list(range(1,16)),wcss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Segment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "\n",
    "\t\t\n",
    "<h4 align = \"center\">\n",
    "Environment Canada    \n",
    "Monthly Values for July - 2015\t\n",
    "</h4>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table {\n",
    "    font-family: arial, sans-serif;\n",
    "    border-collapse: collapse;\n",
    "    width: 100%;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "    border: 1px solid #dddddd;\n",
    "    text-align: left;\n",
    "    padding: 8px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "    background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Name in the table</th>\n",
    "    <th>Meaning</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Stn_Name</font></td>\n",
    "    <td><font color = \"green\"><strong>Station Name</font</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Lat</font></td>\n",
    "    <td><font color = \"green\"><strong>Latitude (North+, degrees)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Long</font></td>\n",
    "    <td><font color = \"green\"><strong>Longitude (West - , degrees)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Prov</td>\n",
    "    <td>Province</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tm</td>\n",
    "    <td>Mean Temperature (°C)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTm</td>\n",
    "    <td>Days without Valid Mean Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>D</td>\n",
    "    <td>Mean Temperature difference from Normal (1981-2010) (°C)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"black\">Tx</font></td>\n",
    "    <td><font color = \"black\">Highest Monthly Maximum Temperature (°C)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTx</td>\n",
    "    <td>Days without Valid Maximum Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"black\">Tn</font></td>\n",
    "    <td><font color = \"black\">Lowest Monthly Minimum Temperature (°C)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTn</td>\n",
    "    <td>Days without Valid Minimum Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S</td>\n",
    "    <td>Snowfall (cm)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwS</td>\n",
    "    <td>Days without Valid Snowfall</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S%N</td>\n",
    "    <td>Percent of Normal (1981-2010) Snowfall</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>P</font></td>\n",
    "    <td><font color = \"green\"><strong>Total Precipitation (mm)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwP</td>\n",
    "    <td>Days without Valid Precipitation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>P%N</td>\n",
    "    <td>Percent of Normal (1981-2010) Precipitation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S_G</td>\n",
    "    <td>Snow on the ground at the end of the month (cm)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Pd</td>\n",
    "    <td>Number of days with Precipitation 1.0 mm or more</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>BS</td>\n",
    "    <td>Bright Sunshine (hours)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwBS</td>\n",
    "    <td>Days without Valid Bright Sunshine</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>BS%</td>\n",
    "    <td>Percent of Normal (1981-2010) Bright Sunshine</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>HDD</td>\n",
    "    <td>Degree Days below 18 °C</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>CDD</td>\n",
    "    <td>Degree Days above 18 °C</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Stn_No</td>\n",
    "    <td>Climate station identifier (first 3 digits indicate   drainage basin, last 4 characters are for sorting alphabetically).</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>NA</td>\n",
    "    <td>Not Available</td>\n",
    "  </tr>\n",
    "\n",
    "\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='weather.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df = df[pd.notnull(df[\"Tm\"])]\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (14,10)\n",
    "llon=-140\n",
    "ulon=-50\n",
    "llat=40\n",
    "ulat=65\n",
    "df = df[(df['Long'] > llon) & (df['Long'] < ulon) & (df['Lat'] > llat) &(df['Lat'] < ulat)]\n",
    "\n",
    "my_map = Basemap(projection='merc',\n",
    "            resolution = 'l', area_thresh = 1000.0,\n",
    "            llcrnrlon=llon, llcrnrlat=llat,\n",
    "            urcrnrlon=ulon, urcrnrlat=ulat) \n",
    "my_map.drawcoastlines()\n",
    "my_map.drawcountries()\n",
    "my_map.shadedrelief()\n",
    "\n",
    "\n",
    "## this is to change longitude and latitude to coordinates\n",
    "\n",
    "xs,ys = my_map(np.asarray(df.Long), np.asarray(df.Lat))\n",
    "df['xm']= xs.tolist()\n",
    "df['ym'] =ys.tolist()\n",
    "\n",
    "# plot the stations on the map\n",
    "for index,row in df.iterrows():\n",
    "    my_map.plot(row.xm, row.ym,markerfacecolor =([1,0,0]),  marker='o', markersize= 5, alpha = 0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following, you'll work on two datasets data1 (segmentation based on location data only) and data2 (segmentation based on location data as well as the temperature data) to perform k means methods with an appropriate k to do clustering and then label the clusters on two separate maps. You need to justify every decisions you make by appropriate plots or reasoning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do not change anything in this block\n",
    "data1= df[['xm','ym']].to_numpy()\n",
    "data2 = df[['xm','ym','Tx','Tm','Tn']].to_numpy()\n",
    "\n",
    "data1 = np.nan_to_num(data1)\n",
    "data1 = StandardScaler().fit_transform(data1)\n",
    "data2 = np.nan_to_num(data2)\n",
    "data2 = StandardScaler().fit_transform(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add your code for problem 3 from part B below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data - see notebook on \"Dimension Reduction, PCA, kernel PCA, Part 1\"\n",
    "\n",
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peform hierarchical clustering on the states using complete linkage clustering \n",
    "# (using Euclidean distance) and plot the corresponding denrogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the states in each cluster and print them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now standardize the data and perform hierarchical clustering as above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a \"reasonable\" partition by considering the dedrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put your answer to Problem 3, part (d) here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Submit both a pdf file and your original jupyter notebook on canvas.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
